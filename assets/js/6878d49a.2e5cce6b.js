"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[1174],{8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>s});var i=t(6540);const o={},a=i.createContext(o);function r(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(a.Provider,{value:n},e.children)}},9354:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-4-vla/week-12-finetuning","title":"Week 12: Fine-tuning","description":"Fine-tuning VLA models for robotics","source":"@site/docs/module-4-vla/week-12-finetuning.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/week-12-finetuning","permalink":"/textbook-hackathon/module-4-vla/week-12-finetuning","draft":false,"unlisted":false,"editUrl":"https://github.com/eDeveloper132/textbook-hackathon/tree/main/docs/module-4-vla/week-12-finetuning.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Week 12: Fine-tuning","description":"Fine-tuning VLA models for robotics"},"sidebar":"tutorialSidebar","previous":{"title":"Week 11: VLA Architecture","permalink":"/textbook-hackathon/module-4-vla/week-11-vla-architecture"},"next":{"title":"Week 13: Deployment","permalink":"/textbook-hackathon/module-4-vla/week-13-deployment"}}');var o=t(4848),a=t(8453);const r={sidebar_position:2,title:"Week 12: Fine-tuning",description:"Fine-tuning VLA models for robotics"},s="Week 12: Fine-tuning for Robotics",l={},c=[{value:"Fine-tuning Strategies",id:"fine-tuning-strategies",level:2},{value:"LoRA Fine-tuning",id:"lora-fine-tuning",level:2},{value:"Data Collection",id:"data-collection",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"week-12-fine-tuning-for-robotics",children:"Week 12: Fine-tuning for Robotics"})}),"\n",(0,o.jsx)(n.p,{children:"Adapt foundation models to your specific robot and tasks."}),"\n",(0,o.jsx)(n.h2,{id:"fine-tuning-strategies",children:"Fine-tuning Strategies"}),"\n",(0,o.jsx)(n.mermaid,{value:'graph TB\n    subgraph "Strategies"\n        FT[Full Fine-tuning]\n        LORA[LoRA]\n        PEFT[Prompt Tuning]\n        HEAD[Head Only]\n    end\n    \n    subgraph "Compute"\n        H[High - 8xA100]\n        M[Medium - 1xA100]\n        L[Low - 1xRTX 3090]\n    end\n    \n    FT --\x3e H\n    LORA --\x3e M\n    PEFT --\x3e L\n    HEAD --\x3e L'}),"\n",(0,o.jsx)(n.h2,{id:"lora-fine-tuning",children:"LoRA Fine-tuning"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from peft import LoraConfig, get_peft_model\n\n# Configure LoRA\nlora_config = LoraConfig(\n    r=16,                    # Rank\n    lora_alpha=32,           # Scaling\n    target_modules=["q_proj", "v_proj"],\n    lora_dropout=0.1,\n    bias="none"\n)\n\n# Apply to model\nmodel = get_peft_model(base_model, lora_config)\n\n# Check trainable parameters\nmodel.print_trainable_parameters()\n# Output: trainable params: 2M || all params: 400M || trainable%: 0.5%\n'})}),"\n",(0,o.jsx)(n.h2,{id:"data-collection",children:"Data Collection"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class RobotDataCollector:\n    def __init__(self, robot, camera):\n        self.robot = robot\n        self.camera = camera\n        self.episodes = []\n    \n    def collect_episode(self, instruction):\n        episode = {\n            "instruction": instruction,\n            "observations": [],\n            "actions": []\n        }\n        \n        while not self.is_done():\n            # Capture observation\n            image = self.camera.capture()\n            episode["observations"].append(image)\n            \n            # Get human demonstration\n            action = self.get_teleop_action()\n            episode["actions"].append(action)\n            \n            # Execute\n            self.robot.execute(action)\n        \n        self.episodes.append(episode)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"LoRA"})," enables efficient fine-tuning"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Demonstrations"})," provide training signal"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Data diversity"})," is crucial"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Evaluation"})," should match deployment"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);