"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[5699],{2154:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"module-4-vla/week-13-deployment","title":"Week 13: Deployment","description":"Deploying VLA models on robots","source":"@site/docs/module-4-vla/week-13-deployment.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/week-13-deployment","permalink":"/textbook-hackathon/module-4-vla/week-13-deployment","draft":false,"unlisted":false,"editUrl":"https://github.com/eDeveloper132/textbook-hackathon/tree/main/docs/module-4-vla/week-13-deployment.mdx","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Week 13: Deployment","description":"Deploying VLA models on robots"},"sidebar":"tutorialSidebar","previous":{"title":"Week 12: Fine-tuning","permalink":"/textbook-hackathon/module-4-vla/week-12-finetuning"},"next":{"title":"Capstone Project","permalink":"/textbook-hackathon/module-4-vla/capstone"}}');var r=t(4848),i=t(8453);const s={sidebar_position:3,title:"Week 13: Deployment",description:"Deploying VLA models on robots"},l="Week 13: Deployment & Integration",a={},d=[{value:"Deployment Pipeline",id:"deployment-pipeline",level:2},{value:"Model Export",id:"model-export",level:2},{value:"ROS2 Inference Node",id:"ros2-inference-node",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"week-13-deployment--integration",children:"Week 13: Deployment & Integration"})}),"\n",(0,r.jsx)(n.p,{children:"Deploy your VLA models on real robot hardware."}),"\n",(0,r.jsx)(n.h2,{id:"deployment-pipeline",children:"Deployment Pipeline"}),"\n",(0,r.jsx)(n.mermaid,{value:'graph LR\n    subgraph "Training"\n        T[Train Model]\n        E[Export ONNX]\n    end\n    \n    subgraph "Optimization"\n        Q[Quantization]\n        O[TensorRT]\n    end\n    \n    subgraph "Deployment"\n        J[Jetson]\n        R[ROS2 Node]\n    end\n    \n    T --\x3e E\n    E --\x3e Q\n    Q --\x3e O\n    O --\x3e J\n    J --\x3e R'}),"\n",(0,r.jsx)(n.h2,{id:"model-export",children:"Model Export"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import torch.onnx\n\ndef export_model(model, save_path):\n    # Dummy inputs\n    dummy_image = torch.randn(1, 3, 224, 224)\n    dummy_text = torch.randint(0, 1000, (1, 77))\n    \n    # Export to ONNX\n    torch.onnx.export(\n        model,\n        (dummy_image, dummy_text),\n        save_path,\n        input_names=['image', 'text'],\n        output_names=['actions'],\n        dynamic_axes={\n            'image': {0: 'batch'},\n            'text': {0: 'batch'}\n        }\n    )\n"})}),"\n",(0,r.jsx)(n.h2,{id:"ros2-inference-node",children:"ROS2 Inference Node"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom std_msgs.msg import String\nimport numpy as np\n\nclass VLAInferenceNode(Node):\n    def __init__(self):\n        super().__init__('vla_inference')\n        \n        # Load model\n        self.model = self.load_tensorrt_model()\n        \n        # Subscribers\n        self.image_sub = self.create_subscription(\n            Image, '/camera/image', self.image_callback, 10)\n        self.instruction_sub = self.create_subscription(\n            String, '/instruction', self.instruction_callback, 10)\n        \n        # Publisher\n        self.action_pub = self.create_publisher(\n            Float32MultiArray, '/robot/action', 10)\n        \n        self.current_instruction = None\n    \n    def instruction_callback(self, msg):\n        self.current_instruction = msg.data\n    \n    def image_callback(self, msg):\n        if self.current_instruction is None:\n            return\n        \n        # Preprocess\n        image = self.preprocess_image(msg)\n        text = self.tokenize(self.current_instruction)\n        \n        # Inference\n        action = self.model.infer(image, text)\n        \n        # Publish\n        action_msg = Float32MultiArray(data=action.tolist())\n        self.action_pub.publish(action_msg)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ONNX"})," provides portable model format"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TensorRT"})," optimizes for NVIDIA hardware"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS2"})," integrates model with robot stack"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Safety"})," must be considered for deployment"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>l});var o=t(6540);const r={},i=o.createContext(r);function s(e){const n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);